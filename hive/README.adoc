= Hive Workshop
<venky@cloudera.com>
v0.2, 2019-08-29: draft
:page-layout: docs
:description: Hive Workshop
:icons: font
:uri-fontawesome: https://fontawesome.com/v4.7.0/
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
:toc:
:toc-placement!:

[colophon]
version: {revnumber}
: {revdate}
: {revremark}

[abstract]


=== What
Hive Workshop, aimed at data warehouse optimisation. Toolset used:

.. hive 3.x (with LLAP)
.. kafka 2.x
.. spark 2.x
.. hwc connectors for kafka, spark

Session is run on a Knox (_optional_) + Ranger enabled kerberized HDP3.x cluster.

=== Pre-Requisites (For Instructors)
. Login to AWS (Hortonworks or Cloudera) with your Okta username and password.
.. AMI, in EU-Frankfurt, `ami-02fd8a7045f9fba17` minimum recommended size m4.2x large.
.. Login user: `centos` | Service user: `etl_user`

. Copy this AMI to your region for better performance. 
.. The AMI contains 
... HortoniaBank demo dataset
... Public and generated datasets for workshop use under the `/home/etl_user/datasets` directory.
.. Public datasets : NYC Taxi Data
+
[source,shell]
----

wget https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip

wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv

wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-04.csv

wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-05.csv

wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2019-06.csv

wget https://github.com/maxis42/Big-Data-Engineering-Coursera-Yandex/raw/master/1%20Big%20data%20essentials/Homeworks/Week%206/data_dictionary_trip_records_yellow.pdf
----
.. Generated data sets use https://github.com/everwatchsolutions/json-data-generator[this] to generate data used in the workshop. The AMI contains the datasets with the required configs.

. Create a new ssh key via ssh-keygen and import it into the required region.This key will be used for giving access to the AMI for participants.Save the public key. If you want to reuse the key combinations used https://github.com/vsellappa/workshop/tree/master/keys[here]. The public key is https://drive.google.com/drive/folders/1D6WKX5UzZrfBW1lW_Vjw7V6U3Az7kyiE?usp=sharing[here]. Attach the public key to your AMI instance. 

. Create the AMI instance in the normal way and attach the previously generated keypair. Ensure that all ports are securely accessible.

+
CAUTION: Venues might have specific ports blocked, check this before-hand. In some cases participant laptops might have restrictive firewalls as well.

. Once the instance is up
.. ssh into the instance
+
[source,bash]
----
ssh -i <.pem file> -l centos <IPAddress> 
----
.. For Ambari:
+
[source,bash]
----
http://<IPAddress:8080> 
username: admin
password: BadPass#1
----

. Convert the .pem or openssh key to .ppk for windows users: https://aws.amazon.com/premiumsupport/knowledge-center/convert-pem-file-into-ppk/[ConvertPEM]
.. Upload the .ppk file to a secure location. (I use private github).
.. This file needs to be handed to the participants.

+ 
NOTE: A working key combination is https://github.com/vsellappa/workshop/tree/master/keys[here]

. https://docs.google.com/presentation/d/1gO60IWO483WgqU5zcP88EZIz0fykuAZ_jeio5yLv98o/edit?usp=sharing[Slidedeck]


=== For Participants
. Change the `/etc/hosts` on your desktop.
.. https://gist.github.com/zenorocha/18b10a14b2deb214dc4ce43a2d2e2992[How-To]
.. Map the given cluster IP Address to `*hdp31.cloudera.com*`

. Connection details
+
----
username/password for ambari: admin/BadPass#1
username for ssh connections: centos
----
.. https://github.com/vsellappa/workshop/tree/master/connect[How To Connect]

. After connecting follow the labs from below.

==== Labs
. https://github.com/vsellappa/workshop/tree/master/hive/Lab101[Lab 101]/ https://github.com/vsellappa/workshop/blob/master/hive/slides/Hive_Lab101_102_Workshop_ToShare.pdf[slides]

. https://github.com/vsellappa/workshop/tree/master/hive/Lab102[Lab 102]
